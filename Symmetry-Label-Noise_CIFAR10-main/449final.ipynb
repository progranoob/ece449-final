{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--lr LR] [--resume]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Administrator\\AppData\\Roaming\\jupyter\\runtime\\kernel-422c3f9a-a070-4f53-9aec-a75398531f68.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from eightlayernet import EightLayerNet\n",
    "from utils import progress_bar\n",
    "from SCELoss import SCELoss\n",
    "from torchvision import datasets\n",
    "from dataloader import cifar10Nosiy\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "parser.add_argument('--lr', default=0.01, type=float, help='learning rate')\n",
    "parser.add_argument('--resume', '-r', action='store_true',\n",
    "                    help='resume from checkpoint')\n",
    "args = parser.parse_args()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "train_dataset = cifar10Nosiy(root='./data',\n",
    "                             train=True,\n",
    "                             transform=transform_train,\n",
    "                             download=True,\n",
    "                             asym=False,\n",
    "                             nosiy_rate=0.6)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./data',\n",
    "                                train=False,\n",
    "                                transform=transform_train,\n",
    "                                download=True)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net = EightLayerNet()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "if args.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/main.pth')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = SCELoss(alpha=0.1, beta=1, num_classes=10)\n",
    "optimizer = optim.SGD(net.parameters(), lr=args.lr,\n",
    "                      momentum=0.9, weight_decay=1e-4)\n",
    "fixed_cnn_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 40, gamma=0.1)\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "        \n",
    "        #SummaryWriter\n",
    "        n_iter = (epoch - 1) * len(trainloader) + batch_idx + 1\n",
    "        writer.add_scalar('Train/loss', loss.item(), n_iter)\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/SCELoss.pth')\n",
    "        best_acc = acc\n",
    "    \n",
    "    #SummaryWriter\n",
    "    writer.add_scalar('Test/Average loss', test_loss, epoch)\n",
    "    writer.add_scalar('Test/Accuracy', acc, epoch)\n",
    "\n",
    "\n",
    "writer = SummaryWriter('log/tensorboard/SCELoss')\n",
    "input_tensor = torch.Tensor(1, 3, 32, 32).cuda()\n",
    "writer.add_graph(net, input_tensor)\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+120):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    fixed_cnn_scheduler.step()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.2-py2.py3-none-any.whl (120 kB)\n",
      "Collecting protobuf>=3.8.0\n",
      "  Downloading protobuf-3.17.0-py2.py3-none-any.whl (173 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorboardX) (1.19.2)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
      "Installing collected packages: protobuf, tensorboardX\n",
      "Successfully installed protobuf-3.17.0 tensorboardX-2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
